import pickle
import numpy as np

with open('word2vec.pickle', 'rb') as f:
    lr = pickle.load(f)
    word2vec = pickle.load(f)


def average_word_vectors(words, model, vocabulary, num_features):
    feature_vector = np.zeros((num_features,), dtype="float64")
    nwords = 0.
    for word in words:
        if word in vocabulary:
            nwords += 1
            feature_vector = np.add(feature_vector, model.wv[word])
    if nwords > 0:
        feature_vector = np.divide(feature_vector, nwords)
    return feature_vector

def preprocess_text(headline, body):
    # Combine headline and body into a single string
    text = f"{headline} {body}"
    #tokenize text
    tokenized_text = text.split()
    features = average_word_vectors(tokenized_text, word2vec, word2vec.wv.key_to_index, 1000)

    # Predict using LogisticRegression model
    lr_pred = lr.predict([features])

    # Make predictions of confidence
    predicted_confidence = lr.predict_proba([features])

    # Get the confidence 
    confidence = round(predicted_confidence.max()*100 ,2 )

    #return both
    return [lr_pred[0],confidence]

# Example new text data
new_headline = "Explaining the 'how' - the launch of BBC Verify"
new_body = '''
In the early hours of Wednesday 3 May, video footage emerged showing what appeared to be two drones crashing into a dome of the Kremlin complex in Moscow. But was the video real or fake? Did this "attack" actually happen? And how could we tell?

The exponential growth of manipulated and distorted video means that seeing is no longer believing. Consumers tell us they can no longer trust that the video in their news feeds is real. Which is why we at the BBC must urgently begin to show and share the work we do behind the scenes, to check and verify information and video content before it appears on our platforms. And as AI weaponises and turbocharges the impact and consequences of disinformation, this work has never been more important.

All day, every day, the BBC's news teams are using ever more sophisticated tools, techniques and technology to check and verify videos like the Kremlin drone footage, as well as images and information. They do this to ensure our journalism meets the rigorous editorial standards the BBC is proud to uphold.

But, until now, that work has largely gone on in the background, unseen by audiences.

BBC Verify: Satellites reveal Russian defences
These same audiences are constantly bombarded with mis- and disinformation, and with fake images, including those generated by AI. And they are telling us that amid this noise and sensationalism, they need to see our workings, so we can maintain the trust people have put in the BBC for the last 100 years. People want to know not just what we know (and don't know), but how we know it.

And this is how our new brand, BBC Verify, has come into being.

Deborah Turness
Image caption,
Deborah Turness, BBC News CEO
We've brought together forensic journalists and expert talent from across the BBC, including our analysis editor Ros Atkins and disinformation correspondent Marianna Spring and their teams. In all, BBC Verify comprises about 60 journalists who will form a highly specialised operation with a range of forensic investigative skills and open source intelligence (Osint) capabilities at their fingertips.

They'll be fact-checking, verifying video, countering disinformation, analysing data and - crucially - explaining complex stories in the pursuit of truth.

This is a different way of doing our journalism. We've built a physical space in the London newsroom, with a studio that BBC Verify correspondents and experts will report from, transparently sharing their evidence-gathering with our audiences. They will contribute to News Online, radio and TV, including the News Channel and our live and breaking streaming operation, both in the UK and internationally.

BBC Verify will be home to specific expertise and technology. But I want the principle of transparently explaining the "how" behind our journalism to be shared by every journalist in the BBC - and thank you to those who are experimenting with new ways to do that.

"If you know how it's made, you can trust what it says" - that's what our audiences have told us. Trust is earned and transparency will help us earn it.

And as for that "drone"? There are a few answers on Ros Atkins' explainer video, which has had more than a million views on our website, and will give people a taste of what Verify will be doing, day in, day out.
'''

# Preprocess the new text data for prediction
print(preprocess_text(new_headline, new_body))


#returned fake